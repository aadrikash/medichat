{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa82ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3889c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0a3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b987c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import pyPDFLoader , DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d22980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c6121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_files(data):\n",
    "    loader=DirectoryLoader(data, glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents=loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f674b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_files(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3955de",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_files(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb66e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data=load_pdf_files(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdf45a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbdbc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_files(data):\n",
    "    loader=DirectoryLoader(data, glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents=loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a93f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_files(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83d5ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_files(data):\n",
    "    loader=DirectoryLoader(data, glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents=loader.load()\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44dc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_files(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690c3062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac90e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "\n",
    "def load_pdf_files(data):\n",
    "    loader = DirectoryLoader(data, glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "\n",
    "extracted_data = load_pdf_files(\"data\")\n",
    "print(len(extracted_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8ba51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b992c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d132d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import list \n",
    "from langchain.schema import Document\n",
    "\n",
    "def filter_minimal_doc(docs: list[Document], min_length: int) -> list[Document]:\n",
    "    \"\"\"\"\n",
    "    given a list of document objects, return a new list of document objects containing only 'source' in metadata and the original page_content.\n",
    "    \"\"\"\n",
    "    minimal_docs: list[document]=[]\n",
    "    for doc in docs:\n",
    "        src= doc.metadata.get(\"source\")\n",
    "        minimal_doc.append(\n",
    "            document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\"source\": src}\n",
    "                )\n",
    "        )\n",
    "    return minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd4972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "def filter_minimal_doc(docs: list[Document], min_length: int) -> list[Document]:\n",
    "    \"\"\"\n",
    "    Given a list of Document objects, return a new list of Document objects\n",
    "    containing only 'source' in metadata and original page_content.\n",
    "    \"\"\"\n",
    "\n",
    "    minimal_docs: list[Document] = []\n",
    "\n",
    "    for doc in docs:\n",
    "        if len(doc.page_content) >= min_length:\n",
    "            src = doc.metadata.get(\"source\")\n",
    "\n",
    "            minimal_docs.append(\n",
    "                Document(\n",
    "                    page_content=doc.page_content,\n",
    "                    metadata={\"source\": src}\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return minimal_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b847ab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_docs = filter_minimal_doc(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import list \n",
    "from langchain.schema import Document\n",
    "\n",
    "def filter_minimal_doc(docs: list[Document], min_length: int) -> list[Document]:\n",
    "    \"\"\"\"\n",
    "    given a list of document objects, return a new list of document objects containing only 'source' in metadata and the original page_content.\n",
    "    \"\"\"\n",
    "    minimal_docs: list[document]=[]\n",
    "    for doc in docs:\n",
    "        src= doc.metadata.get(\"source\")\n",
    "        minimal_doc.append(\n",
    "            document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\"source\": src}\n",
    "                )\n",
    "        )\n",
    "    return minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6448f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = filter_minimal_doc(extracted_data, 100)\n",
    "print(len(filtered))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2d25e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_docs = filter_minimal_doc(extracted_data, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213fea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the document into smaller chunks \n",
    "def text_split(minimal_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "        \n",
    "    )\n",
    "    docs_chunks = text_splitter.split_documents(minimal_docs)\n",
    "    return docs_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e40905",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_chunk = text_split(minimal_docs)\n",
    "print(f\"number of chunks: {len(texts_chunk)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373b469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_chunks = text_split(minimal_docs)\n",
    "print(f\"number of chunks: {len(docs_chunks)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e18bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the document into smaller chunks \n",
    "def text_split(minimal_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "        \n",
    "    )\n",
    "    texts_chunk = text_splitter.split_documents(minimal_docs)\n",
    "    return texts_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12909bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_chunks = text_split(minimal_docs)\n",
    "print(f\"number of chunks: {len(texts_chunks)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aaae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_docs = filter_minimal_doc(extracted_data, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68df96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "def filter_minimal_doc(docs: list[Document], min_length: int = 100):\n",
    "    minimal_docs: list[Document] = []\n",
    "\n",
    "    for doc in docs:\n",
    "        if len(doc.page_content) >= min_length:\n",
    "            src = doc.metadata.get(\"source\")\n",
    "            minimal_docs.append(\n",
    "                Document(\n",
    "                    page_content=doc.page_content,\n",
    "                    metadata={\"source\": src}\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return minimal_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c110acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_docs = filter_minimal_doc(extracted_data, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3c74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.schema import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74f3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_files(data):\n",
    "    loader = DirectoryLoader(data, glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "\n",
    "extracted_data = load_pdf_files(\"data\")\n",
    "print(\"PDFs loaded:\", len(extracted_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eda67d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_minimal_doc(docs: list[Document], min_length: int = 100):\n",
    "    minimal_docs: list[Document] = []\n",
    "\n",
    "    for doc in docs:\n",
    "        if len(doc.page_content) >= min_length:\n",
    "            src = doc.metadata.get(\"source\")\n",
    "            minimal_docs.append(\n",
    "                Document(\n",
    "                    page_content=doc.page_content,\n",
    "                    metadata={\"source\": src}\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return minimal_docs\n",
    "\n",
    "\n",
    "minimal_docs = filter_minimal_doc(extracted_data, 100)\n",
    "print(\"Filtered docs:\", len(minimal_docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5604dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_chunks = text_split(minimal_docs)\n",
    "print(\"Chunks:\", len(texts_chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e04e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def text_split(minimal_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "    )\n",
    "\n",
    "    texts_chunk = text_splitter.split_documents(minimal_docs)\n",
    "    return texts_chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4493eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_chunks = text_split(minimal_docs)\n",
    "print(\"Chunks:\", len(texts_chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab1465",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6791e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embedding import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings():\n",
    "    \"\"\"\n",
    "    Download HuggingFace embeddings model.\n",
    "    \"\"\"\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    return embeddings\n",
    "\n",
    "embedding = download_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac31304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings():\n",
    "    \"\"\"\n",
    "    Download HuggingFace embeddings model.\n",
    "    \"\"\"\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "embedding = download_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373817fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46cb305",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475d68d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = embedding.embed_query(\"hello world\")\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727791c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"vector length:\", len(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f556540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da18d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60888b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"KEY:\", os.getenv(\"OPENAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1764cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcb5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfb1ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a205dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"]=PINECONE_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"]=OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a9b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e358cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"PINECONE:\", PINECONE_API_KEY)\n",
    "print(\"OPENAI:\", OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(os.getenv(\"PINECONE_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3368b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(os.getenv(\"PINECONE_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4fd1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"C:/Users/manja/medichat/.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704823c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.path.exists(\"C:/Users/manja/medichat/.env\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eed52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/manja/medichat/.env\") as f:\n",
    "    print(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3197d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir(\"C:/Users/manja/medichat\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/manja/medichat/.env\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "    print(data)\n",
    "    print(\"Length:\", len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2896d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/manja/medichat/.env\", \"w\") as f:\n",
    "    f.write(\"OPENAI_API_KEY=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\\n\")\n",
    "    f.write(\"PINECONE_API_KEY=pcsk_7HZAky_2SYRXTUijiLZKJCf7y3rECYZt1otrZHNtRaJw9HnH6F7cTrpEC7FMjMqk4RZN2g\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa10d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/manja/medichat/.env\", \"rb\") as f:\n",
    "    print(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f76548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"C:/Users/manja/medichat/.env\", override=True)\n",
    "\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(os.getenv(\"PINECONE_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39523ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecd5f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "INECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79714cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import pinecone\n",
    "pinecone_api_key = PINECONE_API_KEY\n",
    "\n",
    "pc = pinecone(api_key= pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327492d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "import os\n",
    "\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "print(\"Pinecone connected successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9866ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "import os\n",
    "\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b902fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a1b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "index_name = \"medichat\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\",region=\"us-west1\")\n",
    "\n",
    "        )\n",
    "    \n",
    "    index =pc.index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b245ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "index_name = \"medichat\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\",region=\"us-east-1\")\n",
    "\n",
    "        )\n",
    "    \n",
    "    index =pc.index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1218683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "# Initialize your Pinecone object (pc) here...\n",
    "\n",
    "index_name = \"medichat\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\") # Ensure this region is correct for your tier\n",
    "    )\n",
    "\n",
    "# Use capital 'I' for Index\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024a806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=docs_chunks,\n",
    "    embedding=embedding,\n",
    "    index_name=\"medichat\"   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84be6d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5480961e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6bf2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=texts_chunk,\n",
    "    embedding=embedding,\n",
    "    index_name=\"medichat\"   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1517afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# 1. Load your PDF data\n",
    "loader = DirectoryLoader('data/', glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. Split the text into chunks (This creates 'texts_chunk')\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "texts_chunk = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3. Define the embedding model (This creates 'embedding')\n",
    "# Make sure this matches the 384 dimensions you set for your index!\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 4. NOW you can run your Pinecone code\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=texts_chunk,\n",
    "    embedding=embedding,\n",
    "    index_name=\"medichat\"   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd29fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the chunks\n",
    "texts_chunk = text_split(minimal_docs) # Removed the 's' to match your next command\n",
    "print(\"Chunks:\", len(texts_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a69378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. Re-define the function\n",
    "def text_split(minimal_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "    )\n",
    "    texts_chunk = text_splitter.split_documents(minimal_docs)\n",
    "    return texts_chunk\n",
    "\n",
    "# 2. Run the splitting (Make sure minimal_docs is already loaded!)\n",
    "texts_chunk = text_split(minimal_docs)\n",
    "print(\"Chunks created:\", len(texts_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d57c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "\n",
    "# 1. Load the PDF files from your 'data' folder\n",
    "# Make sure your PDFs are inside a folder named 'data' in your project directory\n",
    "loader = DirectoryLoader('data/', glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "\n",
    "# 2. This creates the 'minimal_docs' variable\n",
    "minimal_docs = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(minimal_docs)} pages from your PDFs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37c4b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Current Directory:\", os.getcwd())\n",
    "print(\"Files in this directory:\", os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e3d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'data/' to './' if the PDFs are in the main folder\n",
    "loader = DirectoryLoader('./', glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "minimal_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c6c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. Re-define the function\n",
    "def text_split(minimal_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "    )\n",
    "    texts_chunk = text_splitter.split_documents(minimal_docs)\n",
    "    return texts_chunk\n",
    "\n",
    "# 2. Run the splitting (Make sure minimal_docs is already loaded!)\n",
    "texts_chunk = text_split(minimal_docs)\n",
    "print(\"Chunks created:\", len(texts_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a8ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def text_split(minimal_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "    )\n",
    "\n",
    "    texts_chunk = text_splitter.split_documents(minimal_docs)\n",
    "    return texts_chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ab4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_chunk = text_split(minimal_docs)\n",
    "print(\"Chunks:\", len(texts_chunk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a93fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of documents loaded: {len(minimal_docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6ea482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 1. Check current location\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "\n",
    "# 2. Check if 'data' folder exists here\n",
    "if os.path.exists('data'):\n",
    "    print(\"Found 'data' folder.\")\n",
    "    print(\"Files inside 'data':\", os.listdir('data'))\n",
    "else:\n",
    "    print(\"CANNOT FIND 'data' folder. Listing all files in current directory instead:\")\n",
    "    print(os.listdir('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "\n",
    "# Point to the specific location inside research\n",
    "loader = DirectoryLoader('research/data/', glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "\n",
    "minimal_docs = loader.load()\n",
    "\n",
    "print(f\"Success! Loaded {len(minimal_docs)} pages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def text_split(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "# Create the chunks\n",
    "texts_chunk = text_split(minimal_docs)\n",
    "print(f\"Total chunks created: {len(texts_chunk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324b2ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(\"Embedding model initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9b31b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# 1. LOAD DATA (From your research/data folder)\n",
    "print(\"Loading PDFs...\")\n",
    "loader = DirectoryLoader('research/data/', glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "minimal_docs = loader.load()\n",
    "print(f\"âœ… Loaded {len(minimal_docs)} pages.\")\n",
    "\n",
    "# 2. SPLIT TEXT\n",
    "print(\"Splitting text into chunks...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "texts_chunk = text_splitter.split_documents(minimal_docs)\n",
    "print(f\"âœ… Created {len(texts_chunk)} chunks.\")\n",
    "\n",
    "# 3. INITIALIZE EMBEDDINGS (384 dimensions for your index)\n",
    "print(\"Initializing Embedding Model...\")\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(\"âœ… Embedding model ready.\")\n",
    "\n",
    "# 4. UPLOAD TO PINECONE\n",
    "# Note: Ensure PINECONE_API_KEY is set in your .env or os.environ\n",
    "index_name = \"medichat\"\n",
    "print(f\"Uploading to Pinecone index: {index_name}...\")\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=texts_chunk,\n",
    "    embedding=embedding,\n",
    "    index_name=index_name\n",
    ")\n",
    "print(\"ðŸš€ SUCCESS! Your medical data is now indexed and searchable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad566f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    idex_name=\"medichat\",\n",
    "    embedding=embedding \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83413edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=\"medichat\",\n",
    "    embedding=embedding \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e948068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more data to pinecone index \n",
    "dswith = Document(\n",
    "    page_content=\"This is a new document to be added to the Pinecone index.\",\n",
    "    metadata={\"source\": \"new_doc.pdf\"}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d29ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# Now your code will work:\n",
    "dswith = Document(\n",
    "    page_content=\"This is a new document to be added to the Pinecone index.\",\n",
    "    metadata={\"source\": \"new_doc.pdf\"}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba52cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch.add_documents(documents=  [dswith])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538c9bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5280a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs=retriever.invoke(\"What is diabetes?\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c4a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatmodel = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0209f3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f378f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "\n",
    "    \"you are an medical assistant for question- answering tasks.\"\n",
    "    \"use the folowing pieces of retrieved context to answer\"\n",
    "    \"the question. if you don't know the answer, just say that you don't know, don't try to make up an answer.use three sentences maximum and keep the answer concise.  \"\n",
    "  \"/n/n\"\n",
    "  \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\",\"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aea5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answering_chain = create_stuff_documents_chain(chatmodel,prompt)\n",
    "rag_chain = create_retrieval_chain(retriever,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0454e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answering_chain = create_stuff_documents_chain(chatmodel,prompt)\n",
    "rag_chain = create_retrieval_chain(retriever,question_answering_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090accf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a445e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke(\"input\": \"what is acrogaly and gigantism?\")\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd9f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the input in curly braces {}\n",
    "response = rag_chain.invoke({\"input\": \"what is acromegaly and gigantism?\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec9f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_core\n",
    "import langchain_groq\n",
    "print(f\"Core: {langchain_core.__version__}\")\n",
    "print(f\"Groq: {langchain_groq.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f81f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1. Setup API Key\n",
    "os.environ[\"GROQ_API_KEY\"] = \"PASTE_YOUR_GROQ_KEY_HERE\"\n",
    "\n",
    "# 2. Initialize Groq LLM\n",
    "# Llama 3.3 70B is very powerful and usually free on Groq\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# 3. Define the Prompt (How the bot should behave)\n",
    "system_prompt = (\n",
    "    \"You are a medical assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"If you don't know the answer, say that you don't know. \"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 4. Create the Chain\n",
    "# We assume 'docsearch' (PineconeVectorStore) is already defined from previous cells\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(docsearch.as_retriever(), question_answer_chain)\n",
    "\n",
    "# 5. Ask your question!\n",
    "response = rag_chain.invoke({\"input\": \"What is acromegaly and gigantism?\"})\n",
    "\n",
    "print(\"Medibot Answer:\")\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3eb581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup API Key\n",
    "# Make sure the key is inside quotes and has no extra spaces\n",
    "os.environ[\"GROQ_API_KEY\"] = \"os.getenv(\"GROQ_API_KEY\")_J5TnW4kNk50acseCeZ2qWGdyb3FYBYnvooc5b0PhFbvFfMBQXr2T\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure there is a quote (\") and a parenthesis ()) at the very end\n",
    "os.environ[\"GROQ_API_KEY\"] = os.environ[\"GROQ_API_KEY\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee79cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1. Setup API Key\n",
    "\n",
    "# 2. Initialize Groq LLM\n",
    "# Llama 3.3 70B is very powerful and usually free on Groq\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# 3. Define the Prompt (How the bot should behave)\n",
    "system_prompt = (\n",
    "    \"You are a medical assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"If you don't know the answer, say that you don't know. \"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 4. Create the Chain\n",
    "# We assume 'docsearch' (PineconeVectorStore) is already defined from previous cells\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(docsearch.as_retriever(), question_answer_chain)\n",
    "\n",
    "# 5. Ask your question!\n",
    "response = rag_chain.invoke({\"input\": \"What is acromegaly and gigantism?\"})\n",
    "\n",
    "print(\"Medibot Answer:\")\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# 1. Re-set your keys\n",
    "os.environ[\"GROQ_API_KEY\"] = \"os.getenv(\"GROQ_API_KEY\")_your_actual_key\"\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"your_actual_key\"\n",
    "\n",
    "# 2. Re-connect to your existing work\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "docsearch = PineconeVectorStore(index_name=\"medichat\", embedding=embeddings)\n",
    "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0.3)\n",
    "\n",
    "print(\"âœ… Reconnected! No need to upload PDFs again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38898bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# 1. Re-set your keys\n",
    "os.environ[\"GROQ_API_KEY\"] = \"os.getenv(\"GROQ_API_KEY\")_J5TnW4kNk50acseCeZ2qWGdyb3FYBYnvooc5b0PhFbvFfMBQXr2T\"\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_7HZAky_2SYRXTUijiLZKJCf7y3rECYZt1otrZHNtRaJw9HnH6F7cTrpEC7FMjMqk4RZN2g\"\n",
    "\n",
    "# 2. Re-connect to your existing work\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "docsearch = PineconeVectorStore(index_name=\"medichat\", embedding=embeddings)\n",
    "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0.3)\n",
    "\n",
    "print(\"âœ… Reconnected! No need to upload PDFs again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a730cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1. HARDCODE the key directly for testing (ignore os.environ for now)\n",
    "user_key = \"os.getenv(\"GROQ_API_KEY\")_J5TnW4kNk50acseCeZ2qWGdyb3FYBYnvooc5b0PhFbvFfMBQXr2T\" # Ensure this is your FULL key\n",
    "\n",
    "# 2. Initialize Groq with the api_key parameter\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=user_key, \n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# 3. Setup the rest of the chain\n",
    "system_prompt = (\n",
    "    \"You are a medical assistant. Use the context to answer. \\n\\n {context}\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# Create the chains\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(docsearch.as_retriever(), question_answer_chain)\n",
    "\n",
    "# 4. Try the query again\n",
    "try:\n",
    "    response = rag_chain.invoke({\"input\": \"What is acromegaly and gigantism?\"})\n",
    "    print(\"Medibot Answer:\", response[\"answer\"])\n",
    "except Exception as e:\n",
    "    print(f\"Error still occurring: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637ba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke(\"What is diabetes?\")\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22751c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=rag_chain.invoke({\"input\":\"What is diabetes?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb49845",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke({\"input\":\"what is the treatement of acne?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
